{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0841ad46-9185-45e8-ab7c-8d4c005cc673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflowjs as tfjs\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0fe82-39ee-4578-a196-7fb65609cf9a",
   "metadata": {},
   "source": [
    "# MNIST with simple DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfea0eb3-7c32-4472-9d6c-b6ce067bb523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))  # Shape of the MNIST image is 28 x 28px\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88d91d7-46e3-4542-a04b-7cb32f6abc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train / 255.0).astype(\"float32\")  # Convert from 64-bits to 32 bits.\n",
    "X_test = (X_test / 255.0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c540c0-d8d8-46ee-972f-622d44628501",
   "metadata": {},
   "source": [
    "Note the normalization of the integer (pixes 0-255 to 0-1.0) and the conversion from 64-bits to 32-bits.\n",
    "See [here](basics/001_about_numpy.ipynb) to understand why we cast the type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1445ae7f-fc38-47dd-bf4b-0f19aab8715e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 25s 12ms/step - loss: 0.1817 - acc: 0.9444\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0815 - acc: 0.9746\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0552 - acc: 0.9823\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0442 - acc: 0.9862\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0360 - acc: 0.9882\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0298 - acc: 0.9905\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0254 - acc: 0.9920\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0241 - acc: 0.9930\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0203 - acc: 0.9939\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0174 - acc: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129c28580>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2686d294-80e5-4159-872c-3ebba2ad08d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1046 - acc: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10456586629152298, 0.9804999828338623]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e67556-f841-470f-b754-5f8de73e7ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to tensorflow.js compatible model format.\n",
    "tfjs.converters.save_keras_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "846fe3c7-92e4-4396-ba9a-76c870ead2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c339a16-3046-46b2-916c-86db2a76c94a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The test data is a 28 x 28px pixels image.\n",
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42a0ea3c-6ef1-4067-8220-c4b97a8e9330",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x12f3ac910>, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0]), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f9377ad-9e0a-4162-91cb-e6b15edc65ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.1793539e-21, 1.3493487e-14, 5.3128968e-19, 3.9093845e-12,\n",
       "        1.7087958e-16, 3.0913651e-22, 1.1455523e-23, 1.0000000e+00,\n",
       "        7.0237238e-18, 3.3932559e-12]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(np.array([X_test[0]]))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d690f966-05b1-4401-8257-074ec0a5d83a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ddc8d-fa8d-4c39-af19-52ced6c649bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MNIST with simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5f246c-526f-4efc-af8c-7453ac04b4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflowjs as tfjs\n",
    "from tensorflow.keras import Model, models\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e0aa91-90f3-4f20-a87d-c3c54af7c4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                54090     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,410\n",
      "Trainable params: 54,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"mnist\"):\n",
    "    model = models.load_model(\"mnist\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "084fa9d2-29ce-4c2c-b918-f42709862937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f12106c-4392-4f89-b5de-70997a0a9a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 18s 10ms/step - loss: 0.2255 - acc: 0.9363 - val_loss: 0.0851 - val_acc: 0.9770\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 23s 14ms/step - loss: 0.0854 - acc: 0.9752 - val_loss: 0.0719 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 20s 12ms/step - loss: 0.0632 - acc: 0.9814 - val_loss: 0.0588 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0523 - acc: 0.9843 - val_loss: 0.0574 - val_acc: 0.9842\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0444 - acc: 0.9864 - val_loss: 0.0550 - val_acc: 0.9850\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 18s 11ms/step - loss: 0.0391 - acc: 0.9875 - val_loss: 0.0567 - val_acc: 0.9862\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 18s 10ms/step - loss: 0.0336 - acc: 0.9895 - val_loss: 0.0577 - val_acc: 0.9840\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 26s 15ms/step - loss: 0.0286 - acc: 0.9911 - val_loss: 0.0585 - val_acc: 0.9852\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 22s 13ms/step - loss: 0.0251 - acc: 0.9922 - val_loss: 0.0581 - val_acc: 0.9882\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 20s 12ms/step - loss: 0.0219 - acc: 0.9930 - val_loss: 0.0590 - val_acc: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cc9e1f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use 10% of training data for validation - not trained on.\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e4e3c3-c84a-45b8-9830-35d9346a5845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0586 - acc: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05862118676304817, 0.9837999939918518)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68701e4c-f0a7-4f0f-ace9-286718f28e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.3190038e-11, 6.4454966e-09, 5.5039138e-08, 1.6095122e-06,\n",
       "        9.4495011e-12, 3.2956277e-11, 7.9845082e-19, 9.9999821e-01,\n",
       "        2.6797752e-08, 1.0140601e-07]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(np.array([X_test[0]]))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad57e3a-a891-498c-80bf-0ebf9e603155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "614997ba-269b-4b60-8819-5a46ed1b66e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to tensorflow.js compatible model format.\n",
    "tfjs.converters.save_keras_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0481fb13-8a2e-405c-851f-40cfd4681037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa7628d-dada-4df4-b9fc-5cfad35c089a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAYAAACtWK6eAAAFDUlEQVR4nO3dPYsdVRgH8H9i1KgIoqC2go2FXyCNX8DS1tbUEQ2Cn0CwErUI9oIggoWghSCYQrTQRoQEVFBRYjRIVrNJ9q7F7DXZ9SbZuTNzztyZ3w8OpMjdeeblmeecOfOSAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwSeeT7CRZ7LXdgo2BHKsdwIbbTnJP7SAYztHaAWygZ3OjQkiOiVNBDm+R5EjtIChLgtyZxJgxXaxbu56mGyU5ZkwFWU3VIIkEOUhisI8EucF8Av9jDNJY1A6AcZIgjSG7VcvZ7u0kD+0t6zBNRRsBXax+q8dunHQmxc5stkGXs/Vuki/TnPX73J4uFoyAnbDfYa9i7Sa5muT4QHG0SVhVa0C6WPstD7TbJcp2hkuMpH01M1YZkARZbVWilDhTr3OwP917FPxHF+vOloP4MSZHYh8OysYdhy7dJPtwQAZ39XW5zCw5BiZB6trJ+ge55ChAgtSzlfW3v+QoRILU8UqS+9f8reQoyMauwxWrDaGClCc5NogEKefdSI6NYya9jJ2sfzJ6sc9AYGy6vGXxVIV4oZgurxO9VD5cDtK3HU7XZ0yMD0fAThiG5JgIFaR/XZ/PsE9GxJmqX10rh+QYGQnSjwvRrZokZ6zuur6N8XKSB3uKBUajj69ImQQcORWkvb7e32vbbwD93vYkx4xIkPIkxwaRIOUt0rxbiw0gQco7kubjn8uB+iLJj1Ujgh4N/c3zRZKPiq0N9GzoBDmYLC+UWS1WMWBsr9a7cC8kebTSsmdLgrRX+zuGu0kejudFijBIb+9o6n4B6kiSP9Mk6seVYpgNFaS72hUlSa4kua9yDJOkgnS3rChfpV5VOZ4bg3p6VPvMN2VbWf/tiV1dT3J3pWVPigoynAdy44u1p1O2uhzbW97PBZcJvfks/dwuf9j2XZnVgmH8lDKTjmdKrRAMZehkWSR5stjawEBOZdhumCteTMaQifJ2wfXYOC7zbpaLaW4z6dsiyV0D/F2o4tUMU1XeK7kSMLTT6T9RjE2YnC/SfzWByVm+4VElgdv4K/0kyZXSgUNJfYxPfiseNRT0TLonylvFo4bCPk+3JJnlC7ZNFM5PlycgZ3e8eB5kfo4m+XTN387uytbszgjss858x6yOGRVk3l5b4zdP9B4FjFjb509+qRMm1LMVM+wrzao/yW21GY/M5rgxBmHJDYorSBCWLtcOAMasze0opyrFWNxs+pLckTHICrpYJMmHLf6vsQqz8nXazYO0SaaNN5tSyUrbaT4o2sasjhldrHk6maYatE0O3Ssm7+us/0zIrLpXzMuZJDvp9tAUTMrZ9PferJ3CscMgfk8/CXGwnSy5Emy2f5J8n+SN2oEkeT7t7sZt27bLrQpT8FxufRv4VppPNJ9N8n6SE2v8/dfTDKSX7dpNreRXqXb3lg+t/JqyB2mtpkuV5mOPHN65JI/VDmJgV5PcWzuIsTBReHjnMv1Pl30TycEazqV+l0eXqoJZ3VezpqlXjj+SPFI7CDbTO6l/Zh+i/Z3m8jB0dj71D+g+2sW+NwwsfZDkUuof5G3aIs18DBT1ZpIf0kzc1U6Cg+1ampsS6YlBencnkryc5PEkT6V5xuJ4+tu2y2qw9O1N//4kyUs9LQcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgLH7F6V5/5sZKiWUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=200x200>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"three.png\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445c10e1-0e9e-425b-98fd-be65db71f1d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_transparency(im, bg_color=(255, 255, 255)):\n",
    "    # Only process if image has transparency.\n",
    "    if im.mode in (\"RGBA\", \"LA\") or (im.mode == \"P\" and \"transparency\" in im.info):\n",
    "        # Need to convert to RGBA if LA format due to a bug in PIL.\n",
    "        alpha = im.convert(\"RGBA\").split()[-1]\n",
    "\n",
    "        # Create a new background image.\n",
    "        bg = Image.new(\"RGBA\", im.size, bg_color + (255,))\n",
    "        bg.paste(im, mask=alpha)\n",
    "        return bg\n",
    "    else:\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc4f28a2-6ca4-4292-81bf-c948793b3c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15bfda760>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resize the image to fit the input size 28 x 28px.\n",
    "img = img.resize((28, 28))\n",
    "\n",
    "# Convert image to grayscale (removing transparency)\n",
    "# See https://stackoverflow.com/questions/44997339/convert-python-image-to-single-channel-from-rgb-using-pil-or-scipy\n",
    "gray = remove_transparency(img).convert(\"L\")\n",
    "plt.imshow(gray, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5feea41e-ab9b-451f-851c-9fcf4429b02a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.keras.utils.img_to_array(gray)\n",
    "x = 255 - x\n",
    "x = x / 255\n",
    "# x = tf.expand_dims(x, 0)  # Convert to 4d Tensor\n",
    "x = x[np.newaxis, ...]  # Similar to expand_dims\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab4dca4f-34c4-4e7f-9ff5-7f0a5f71d96b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
